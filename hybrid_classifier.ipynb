{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/peluz/victor-visual-text/fastai2/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.text.all import *\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import get_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from os.path import join, split, splitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "# tensorflow RNG\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 500 # Size of input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path(\"./models/\")\n",
    "weights_path = models_path/\"stf_no_weights.keras\"\n",
    "json_path = models_path/\"cnn_text.json\"\n",
    "tokenizer_path = models_path/\"tokenizer.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/mnt/nas/backups/08-07-2020/desktopg01/lisa/Data/CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_path/\"test_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tokenizer_path, 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(test_data['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sequence.pad_sequences(sequences_test, maxlen=SEQUENCE_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_data['document_type'] \n",
    "test_label_toTest = encoder.fit_transform(test_label)\n",
    "test_label = np.transpose(test_label_toTest)\n",
    "test_label = to_categorical(test_label)\n",
    "\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2986/2986 [==============================] - 312s 104ms/step\n"
     ]
    }
   ],
   "source": [
    "json_file = open(json_path,'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "with tf.device('/cpu:0'):\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(weights_path)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    preds = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95526,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/mnt/nas/backups/08-07-2020/desktopg01/lisa/Data/small_flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = get_image_files(path, folders=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = set((test_data[\"file_name\"].str.slice(stop=-4) + \"_\" + test_data[\"pages\"].astype(str)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items_filtered = [x for x in test_items if x.with_suffix(\"\").name not in text_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8037"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_items_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(path, 64, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = dls.test_dl(test_items_filtered, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet50, loss_func=CrossEntropyLossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7ff9048cd490>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"best_image_weights_224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_img, labels_img = learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8037])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_img = preds_img.argmax(dim=-1); preds_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103563,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.concatenate([preds_text, preds_img]); preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103563,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.concatenate([test_label_toTest, labels_img]); labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "          acordao_de_2_instancia     0.2692    0.8920    0.4136       287\n",
      "agravo_em_recurso_extraordinario     0.4408    0.5522    0.4902      2655\n",
      "     despacho_de_admissibilidade     0.3543    0.5377    0.4271       199\n",
      "                          outros     0.9655    0.9507    0.9580     92533\n",
      "                   peticao_do_RE     0.7144    0.7278    0.7211      6386\n",
      "                        sentenca     0.7800    0.7053    0.7407      1503\n",
      "\n",
      "                        accuracy                         0.9222    103563\n",
      "                       macro avg     0.5874    0.7276    0.6251    103563\n",
      "                    weighted avg     0.9307    0.9222    0.9258    103563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['acordao_de_2_instancia','agravo_em_recurso_extraordinario', 'despacho_de_admissibilidade', 'outros', 'peticao_do_RE', 'sentenca']\n",
    "print(classification_report(labels, preds, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "          acordao_de_2_instancia     0.0204    1.0000    0.0400        14\n",
      "agravo_em_recurso_extraordinario     0.2910    0.7654    0.4217       814\n",
      "     despacho_de_admissibilidade     0.0000    0.0000    0.0000         1\n",
      "                          outros     0.9729    0.5846    0.7303      7125\n",
      "                   peticao_do_RE     0.0143    0.1455    0.0260        55\n",
      "                        sentenca     0.0144    0.1071    0.0253        28\n",
      "\n",
      "                        accuracy                         0.5989      8037\n",
      "                       macro avg     0.2188    0.4338    0.2072      8037\n",
      "                    weighted avg     0.8922    0.5989    0.6905      8037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels_img, preds_img, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "          acordao_de_2_instancia     0.9132    0.8864    0.8996       273\n",
      "agravo_em_recurso_extraordinario     0.7114    0.4579    0.5572      1841\n",
      "     despacho_de_admissibilidade     0.7535    0.5404    0.6294       198\n",
      "                          outros     0.9651    0.9813    0.9731     85408\n",
      "                   peticao_do_RE     0.7804    0.7329    0.7559      6331\n",
      "                        sentenca     0.9191    0.7166    0.8053      1475\n",
      "\n",
      "                        accuracy                         0.9494     95526\n",
      "                       macro avg     0.8405    0.7193    0.7701     95526\n",
      "                    weighted avg     0.9467    0.9494    0.9472     95526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label_toTest, preds_text, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7ff9048cd490>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"img_model_no_weights/best_image_no_weights_224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_img, labels_img = learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8037])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_img = preds_img.argmax(dim=-1); preds_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103563,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.concatenate([preds_text, preds_img]); preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103563,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.concatenate([test_label_toTest, labels_img]); labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "          acordao_de_2_instancia     0.9132    0.8432    0.8768       287\n",
      "agravo_em_recurso_extraordinario     0.7114    0.3175    0.4391      2655\n",
      "     despacho_de_admissibilidade     0.7279    0.5377    0.6185       199\n",
      "                          outros     0.9585    0.9821    0.9702     92533\n",
      "                   peticao_do_RE     0.7742    0.7274    0.7500      6386\n",
      "                        sentenca     0.9191    0.7033    0.7968      1503\n",
      "\n",
      "                        accuracy                         0.9441    103563\n",
      "                       macro avg     0.8340    0.6852    0.7419    103563\n",
      "                    weighted avg     0.9396    0.9441    0.9395    103563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['acordao_de_2_instancia','agravo_em_recurso_extraordinario', 'despacho_de_admissibilidade', 'outros', 'peticao_do_RE', 'sentenca']\n",
    "print(classification_report(labels, preds, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "          acordao_de_2_instancia     0.0000    0.0000    0.0000        14\n",
      "agravo_em_recurso_extraordinario     0.0000    0.0000    0.0000       814\n",
      "     despacho_de_admissibilidade     0.0000    0.0000    0.0000         1\n",
      "                          outros     0.8863    0.9924    0.9364      7125\n",
      "                   peticao_do_RE     0.0926    0.0909    0.0917        55\n",
      "                        sentenca     0.0000    0.0000    0.0000        28\n",
      "\n",
      "                        accuracy                         0.8804      8037\n",
      "                       macro avg     0.1632    0.1806    0.1714      8037\n",
      "                    weighted avg     0.7864    0.8804    0.8307      8037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/peluz/victor-visual-text/fastai2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels_img, preds_img, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
