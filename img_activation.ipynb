{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.text.all import *\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import get_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "# # tensorflow RNG\n",
    "# tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/mnt/nas/backups/08-07-2020/desktopg01/lisa/Data/small_flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(path, 64, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = get_image_files(path, folders=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = dls.test_dl(test_items, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetActs(HookCallback):\n",
    "    def __init__(self, modules=None, remove_end=True, detach=True, cpu=True):\n",
    "        super().__init__(modules, None, remove_end, True, detach, cpu)\n",
    "        self.acts = L()\n",
    "    def hook(self, m, i, o): return o\n",
    "    def after_pred(self): self.acts += self.hooks.stored\n",
    "    def before_fit(self):\n",
    "        super().before_fit()\n",
    "        self.acts = L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet50, loss_func=CrossEntropyLossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7fb9015bcc40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.add_cb(GetActs([learn.model[1][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7fb9015bcc40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"best_image_weights_224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#1) [0.3971825838088989]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = learn.get_acts.acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([102997, 4096])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds = torch.cat(list(valid_preds)); valid_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(valid_preds) == len(dls.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 45661\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 98900\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(dls.valid.items):\n",
    "    filename = Path(\"./activations/img\")/re.search(r'val\\/[^\\/]*\\/[^.]*',item.as_posix())[0]\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(valid_preds[idx].clone(), filename.as_posix() + \".pt\")\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.train.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train.get_idxs()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(TensorImage([[1.5496e-01, 9.4552e-03, 1.6290e-02, 6.1323e-01, 3.0069e-02, 1.7599e-01],\n",
       "         [8.0321e-02, 6.5189e-03, 7.0756e-02, 7.5476e-01, 1.0702e-02, 7.6943e-02],\n",
       "         [2.4597e-02, 9.5386e-03, 7.1015e-03, 8.7932e-01, 4.3612e-02, 3.5828e-02],\n",
       "         ...,\n",
       "         [4.3153e-04, 1.7354e-04, 9.5573e-04, 7.0746e-02, 1.1550e-03, 9.2654e-01],\n",
       "         [3.5124e-02, 5.4816e-02, 9.0227e-03, 7.9092e-01, 7.5193e-02, 3.4928e-02],\n",
       "         [5.3208e-02, 7.5849e-03, 1.6632e-02, 5.4792e-01, 2.4147e-02, 3.5051e-01]]),\n",
       " TensorCategory([0, 0, 0,  ..., 5, 5, 5]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.get_preds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = learn.get_acts.acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([158308, 4096])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = torch.cat(list(train_preds)); train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_preds) == len(dls.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 2806\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 158308\r"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(dls.train.items):\n",
    "    filename = Path(\"./activations/img\")/re.search(r'train\\/[^\\/]*\\/[^.]*',item.as_posix())[0]\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(train_preds[idx].clone(), filename.as_posix() + \".pt\")\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(TensorImage([[0.0026, 0.0408, 0.0011, 0.8655, 0.0784, 0.0116],\n",
       "         [0.0033, 0.0198, 0.0010, 0.9566, 0.0157, 0.0036],\n",
       "         [0.0361, 0.0530, 0.0088, 0.8587, 0.0174, 0.0260],\n",
       "         ...,\n",
       "         [0.0252, 0.0195, 0.0184, 0.8575, 0.0319, 0.0474],\n",
       "         [0.0036, 0.0109, 0.0010, 0.9016, 0.0717, 0.0112],\n",
       "         [0.0480, 0.0090, 0.0418, 0.6294, 0.0117, 0.2600]]),\n",
       " TensorCategory([0, 0, 0,  ..., 5, 5, 5]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = learn.get_acts.acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98577, 4096])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = torch.cat(list(test_preds)); test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_preds) == len(test_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 98577\r"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(test_dl.items):\n",
    "    filename = Path(\"./activations/img\")/re.search(r'test\\/[^\\/]*\\/[^.]*',item.as_posix())[0]\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(test_preds[idx].clone(), filename.as_posix() + \".pt\")\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
