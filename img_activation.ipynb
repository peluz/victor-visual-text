{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.text.all import *\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import get_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "# # tensorflow RNG\n",
    "# tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/mnt/nas/backups/08-07-2020/desktopg01/lisa/Data/small_flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(path, 64, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = get_image_files(path, folders=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = dls.test_dl(test_items, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetActs(HookCallback):\n",
    "    def __init__(self, modules=None, remove_end=True, detach=True, cpu=True):\n",
    "        super().__init__(modules, None, remove_end, True, detach, cpu)\n",
    "        self.acts = L()\n",
    "    def hook(self, m, i, o): return o\n",
    "    def after_pred(self): self.acts += self.hooks.stored\n",
    "    def before_fit(self):\n",
    "        super().before_fit()\n",
    "        self.acts = L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet50, loss_func=CrossEntropyLossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f9199de5430>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.add_cb(GetActs([learn.model[1][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f9199de5430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"best_image_weights_224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#1) [1.1870307922363281]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = learn.get_acts.acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([102997, 4096])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds = torch.cat(list(valid_preds)); valid_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(valid_preds) == len(dls.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 102997\r"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(dls.valid.items):\n",
    "    filename = Path(\"./activations/img\")/re.search(r'val\\/[^\\/]*\\/[^.]*',item.as_posix())[0]\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(valid_preds[idx].clone(), filename.as_posix() + \".pt\")\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.train.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train.get_idxs()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(TensorImage([[9.4377e-01, 4.6239e-04, 2.6300e-03, 2.7966e-03, 2.3224e-04, 5.0113e-02],\n",
       "         [9.9129e-01, 4.6016e-04, 1.4170e-03, 5.0892e-03, 3.4972e-04, 1.3904e-03],\n",
       "         [9.6137e-01, 1.6679e-03, 7.2716e-03, 1.0404e-02, 1.2957e-03, 1.7993e-02],\n",
       "         ...,\n",
       "         [1.7435e-04, 3.8101e-05, 2.0885e-04, 3.6850e-04, 2.2262e-04, 9.9899e-01],\n",
       "         [4.3517e-02, 1.9101e-01, 9.1897e-02, 1.7730e-01, 3.0745e-01, 1.8883e-01],\n",
       "         [1.7257e-02, 1.8537e-03, 1.1543e-02, 2.6991e-02, 1.7678e-02, 9.2468e-01]]),\n",
       " TensorCategory([0, 0, 0,  ..., 5, 5, 5]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.get_preds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = learn.get_acts.acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([158308, 4096])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = torch.cat(list(train_preds)); train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_preds) == len(dls.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 158308\r"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(dls.train.items):\n",
    "    filename = Path(\"./activations/img\")/re.search(r'train\\/[^\\/]*\\/[^.]*',item.as_posix())[0]\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(train_preds[idx].clone(), filename.as_posix() + \".pt\")\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(TensorImage([[0.1436, 0.3127, 0.0666, 0.1007, 0.0941, 0.2823],\n",
       "         [0.6757, 0.0645, 0.0299, 0.1373, 0.0516, 0.0410],\n",
       "         [0.9433, 0.0076, 0.0178, 0.0195, 0.0044, 0.0075],\n",
       "         ...,\n",
       "         [0.0601, 0.2577, 0.0815, 0.1288, 0.0345, 0.4374],\n",
       "         [0.0750, 0.0357, 0.0938, 0.2608, 0.1918, 0.3430],\n",
       "         [0.0069, 0.0378, 0.0884, 0.0292, 0.0106, 0.8271]]),\n",
       " TensorCategory([0, 0, 0,  ..., 5, 5, 5]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = learn.get_acts.acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98577, 4096])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = torch.cat(list(test_preds)); test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_preds) == len(test_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 98577\r"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(test_dl.items):\n",
    "    filename = Path(\"./activations/img\")/re.search(r'test\\/[^\\/]*\\/[^.]*',item.as_posix())[0]\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(test_preds[idx].clone(), filename.as_posix() + \".pt\")\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
