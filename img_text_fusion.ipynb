{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.text.all import *\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIM=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./activations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#359882) [Path('activations/valid/agravo_em_recurso_extraordinario/ARE_957523_309003212_1420_21032016_5.activations'),Path('activations/valid/agravo_em_recurso_extraordinario/ARE_811832_4448371_1420_18052014_17.activations'),Path('activations/valid/agravo_em_recurso_extraordinario/ARE_1053618_311977154_1420_07062017_63.activations'),Path('activations/valid/agravo_em_recurso_extraordinario/ARE_1066591_312429859_1420_11082017_9.activations'),Path('activations/valid/agravo_em_recurso_extraordinario/ARE_1071533_312604954_1420_30082017_6.activations'),Path('activations/valid/agravo_em_recurso_extraordinario/ARE_1105199_313609724_1420_04022018_13.activations'),Path('activations/valid/agravo_em_recurso_extraordinario/ARE_1010513_310734552_1420_07022017_5.activations'),Path('activations/valid/agravo_em_recurso_extraordinario/ARE_1056724_312077006_1420_27062017_10.activations'),Path('activations/valid/agravo_em_recurso_extraordinario/ARE_1115582_313936746_1420_16032018_5.activations'),Path('activations/valid/agravo_em_recurso_extraordinario/ARE_1101826_313537521_1420_20122017_9.activations')...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_files(path); files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorToTorch(Transform):\n",
    "    def encodes(self, x):\n",
    "        with open(x, \"rb\") as file:\n",
    "            t = pickle.load(file)\n",
    "        return tensor(np.array(t)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [TensorToTorch(),[parent_label, Categorize()]]\n",
    "splits = GrandparentSplitter(valid_name='valid')(files)\n",
    "dsets = Datasets(files, tfms, splits=splits)\n",
    "dls = dsets.dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#158308) [(tensor([0.8886, 0.0510, 0.0319, 0.0047, 0.0214, 0.0023, 0.8886, 0.0510, 0.0319,\n",
       "        0.0047, 0.0214, 0.0023]), TensorCategory(1)),(tensor([0.7876, 0.1109, 0.0576, 0.0051, 0.0336, 0.0053, 0.7876, 0.1109, 0.0576,\n",
       "        0.0051, 0.0336, 0.0053]), TensorCategory(1)),(tensor([0.8681, 0.0575, 0.0409, 0.0046, 0.0260, 0.0030, 0.8681, 0.0575, 0.0409,\n",
       "        0.0046, 0.0260, 0.0030]), TensorCategory(1)),(tensor([0.9497, 0.0156, 0.0154, 0.0050, 0.0132, 0.0011, 0.9497, 0.0156, 0.0154,\n",
       "        0.0050, 0.0132, 0.0011]), TensorCategory(1)),(tensor([0.9470, 0.0215, 0.0138, 0.0033, 0.0132, 0.0012, 0.9470, 0.0215, 0.0138,\n",
       "        0.0033, 0.0132, 0.0012]), TensorCategory(1)),(tensor([0.8549, 0.0694, 0.0416, 0.0047, 0.0260, 0.0033, 0.8549, 0.0694, 0.0416,\n",
       "        0.0047, 0.0260, 0.0033]), TensorCategory(1)),(tensor([0.9342, 0.0288, 0.0177, 0.0041, 0.0138, 0.0014, 0.9342, 0.0288, 0.0177,\n",
       "        0.0041, 0.0138, 0.0014]), TensorCategory(1)),(tensor([0.7947, 0.1064, 0.0623, 0.0055, 0.0261, 0.0052, 0.7947, 0.1064, 0.0623,\n",
       "        0.0055, 0.0261, 0.0052]), TensorCategory(1)),(tensor([0.9009, 0.0449, 0.0276, 0.0045, 0.0202, 0.0019, 0.9009, 0.0449, 0.0276,\n",
       "        0.0045, 0.0202, 0.0019]), TensorCategory(1)),(tensor([0.8597, 0.0677, 0.0415, 0.0046, 0.0234, 0.0031, 0.8597, 0.0677, 0.0415,\n",
       "        0.0046, 0.0234, 0.0031]), TensorCategory(1))...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits = GrandparentSplitter(valid_name='test')(files)\n",
    "test_dsets = Datasets(files, tfms, splits=test_splits)\n",
    "test_dls = test_dsets.dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgTextFusion(Module):\n",
    "    def __init__(self, head):\n",
    "        self.head = head\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_head(nf, n_out, lin_ftrs=None, ps=0.5, bn_final=False, lin_first=False):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and out `n_out` classes.\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=True, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = create_head(12, OUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImgTextFusion(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(out, targ):\n",
    "    return CrossEntropyLossFlat()(out, targ.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore = F1Score(average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=loss_func, metrics=[accuracy, fscore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model(dls.one_batch()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 3e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
