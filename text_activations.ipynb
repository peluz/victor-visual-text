{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.text.all import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from os.path import join, split, splitext\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "# tensorflow RNG\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 500 # Size of input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path(\"./models/\")\n",
    "weights_path = models_path/\"stf_no_weights.keras\"\n",
    "json_path = models_path/\"cnn_text.json\"\n",
    "tokenizer_path = models_path/\"tokenizer.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(json_path,'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/mnt/nas/backups/08-07-2020/desktopg01/lisa/Data/CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path/\"train_small.csv\")\n",
    "val = pd.read_csv(data_path/\"validation_small.csv\")\n",
    "test_data = pd.read_csv(data_path/\"test_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tokenizer_path, 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(train['body'])\n",
    "sequences_validation = tokenizer.texts_to_sequences(val['body'])\n",
    "sequences_test = tokenizer.texts_to_sequences(test_data['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(sequences_train, maxlen=SEQUENCE_LEN, padding='post')\n",
    "X_val = sequence.pad_sequences(sequences_validation, maxlen=SEQUENCE_LEN, padding='post')\n",
    "X_test = sequence.pad_sequences(sequences_test, maxlen=SEQUENCE_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train['document_type'] \n",
    "train_label_toTest = encoder.fit_transform(train_label)\n",
    "train_label = np.transpose(train_label_toTest)\n",
    "train_label = to_categorical(train_label)\n",
    "\n",
    "\n",
    "valid_label = val['document_type'] \n",
    "valid_label_toTest = encoder.fit_transform(valid_label)\n",
    "valid_label = np.transpose(valid_label_toTest)\n",
    "valid_label = to_categorical(valid_label)\n",
    "\n",
    "test_label = test_data['document_type'] \n",
    "test_label_toTest = encoder.fit_transform(test_label)\n",
    "test_label = np.transpose(test_label_toTest)\n",
    "test_label = to_categorical(test_label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2986/2986 [==============================] - 20s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predict_1 = model.predict(X_test, verbose=1)\n",
    "pred_1 = test_predict_1.argmax(axis=1)\n",
    "target_names = ['acordao_de_2_instancia','agravo_em_recurso_extraordinario', 'despacho_de_admissibilidade', 'outros', 'peticao_do_RE', 'sentenca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "          acordao_de_2_instancia     0.9132    0.8864    0.8996       273\n",
      "agravo_em_recurso_extraordinario     0.7114    0.4579    0.5572      1841\n",
      "     despacho_de_admissibilidade     0.7535    0.5404    0.6294       198\n",
      "                          outros     0.9651    0.9813    0.9731     85408\n",
      "                   peticao_do_RE     0.7804    0.7329    0.7559      6331\n",
      "                        sentenca     0.9191    0.7166    0.8053      1475\n",
      "\n",
      "                        accuracy                         0.9494     95526\n",
      "                       macro avg     0.8405    0.7193    0.7701     95526\n",
      "                    weighted avg     0.9467    0.9494    0.9472     95526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label_toTest, pred_1, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 500, 100)     7000000     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 500, 256)     77056       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 500, 256)     102656      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 500, 256)     128256      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 250, 256)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 250, 256)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 250, 256)     0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 750, 256)     0           max_pooling1d_12[0][0]           \n",
      "                                                                 max_pooling1d_13[0][0]           \n",
      "                                                                 max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 15, 256)      0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3840)         0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          491648      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 6)            774         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,800,390\n",
      "Trainable params: 7,800,390\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'flatten_3/Reshape:0' shape=(None, 3840) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_output = model.layers[-4].output; activation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_4:0' shape=(None, 500) dtype=int32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = model.input; inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_model = tf.keras.Model(inputs, activation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4664/4664 [==============================] - 34s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "train_vecs = activation_model.predict(X_train, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2961/2961 [==============================] - 20s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "val_vecs = activation_model.predict(X_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2986/2986 [==============================] - 21s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test_vecs = activation_model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149217, 3840), (94735, 3840), (95526, 3840))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs.shape, val_vecs.shape, test_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 149217\r"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "for idx, item in train.iterrows():\n",
    "    filename = (Path(\"./activations/text/train\")/Path(item[\"document_type\"])/\n",
    "               (Path(item[\"file_name\"]).with_suffix(\"\").as_posix()+\"_\"+str(item[\"pages\"])))\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(filename, train_vecs[idx])\n",
    "    train_files.append(filename)\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"activation_path\"] = train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.load(\"./activations/text/train/outros/AI_856934_1926211_34_17072013_3.npy\") == train_vecs[3]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 94735\r"
     ]
    }
   ],
   "source": [
    "val_files = []\n",
    "for idx, item in val.iterrows():\n",
    "    filename = (Path(\"./activations/text/val\")/Path(item[\"document_type\"])/\n",
    "               (Path(item[\"file_name\"]).with_suffix(\"\").as_posix()+\"_\"+str(item[\"pages\"])))\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(filename, val_vecs[idx])\n",
    "    val_files.append(filename)\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val[\"activation_path\"] = val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 95526\r"
     ]
    }
   ],
   "source": [
    "test_files = []\n",
    "for idx, item in test_data.iterrows():\n",
    "    filename = (Path(\"./activations/text/test\")/Path(item[\"document_type\"])/\n",
    "               (Path(item[\"file_name\"]).with_suffix(\"\").as_posix()+\"_\"+str(item[\"pages\"])))\n",
    "#     filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     np.save(filename, test_vecs[idx])\n",
    "    test_files.append(filename)\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"activation_path\"] = test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"./data/train_fusion.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv(\"./data/val_fusion.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"./data/test_fusion.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
