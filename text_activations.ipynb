{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.text.all import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from os.path import join, split, splitext\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "# tensorflow RNG\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 500 # Size of input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path(\"./models/\")\n",
    "weights_path = models_path/\"stf_weights.keras\"\n",
    "json_path = models_path/\"cnn_text.json\"\n",
    "tokenizer_path = models_path/\"tokenizer.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(json_path,'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/mnt/nas/backups/08-07-2020/desktopg01/lisa/Data/CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path/\"train_small.csv\")\n",
    "val = pd.read_csv(data_path/\"validation_small.csv\")\n",
    "test_data = pd.read_csv(data_path/\"test_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tokenizer_path, 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(train['body'])\n",
    "sequences_validation = tokenizer.texts_to_sequences(val['body'])\n",
    "sequences_test = tokenizer.texts_to_sequences(test_data['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(sequences_train, maxlen=SEQUENCE_LEN, padding='post')\n",
    "X_val = sequence.pad_sequences(sequences_validation, maxlen=SEQUENCE_LEN, padding='post')\n",
    "X_test = sequence.pad_sequences(sequences_test, maxlen=SEQUENCE_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train['document_type'] \n",
    "train_label_toTest = encoder.fit_transform(train_label)\n",
    "train_label = np.transpose(train_label_toTest)\n",
    "train_label = to_categorical(train_label)\n",
    "\n",
    "\n",
    "valid_label = val['document_type'] \n",
    "valid_label_toTest = encoder.fit_transform(valid_label)\n",
    "valid_label = np.transpose(valid_label_toTest)\n",
    "valid_label = to_categorical(valid_label)\n",
    "\n",
    "test_label = test_data['document_type'] \n",
    "test_label_toTest = encoder.fit_transform(test_label)\n",
    "test_label = np.transpose(test_label_toTest)\n",
    "test_label = to_categorical(test_label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2986/2986 [==============================] - 21s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predict_1 = model.predict(X_test, verbose=1)\n",
    "pred_1 = test_predict_1.argmax(axis=1)\n",
    "target_names = ['acordao_de_2_instancia','agravo_em_recurso_extraordinario', 'despacho_de_admissibilidade', 'outros', 'peticao_do_RE', 'sentenca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "          acordao_de_2_instancia     0.7716    0.9158    0.8375       273\n",
      "agravo_em_recurso_extraordinario     0.6331    0.5595    0.5940      1841\n",
      "     despacho_de_admissibilidade     0.7566    0.5808    0.6571       198\n",
      "                          outros     0.9658    0.9827    0.9742     85408\n",
      "                   peticao_do_RE     0.8479    0.7060    0.7705      6331\n",
      "                        sentenca     0.8591    0.7275    0.7878      1475\n",
      "\n",
      "                        accuracy                         0.9513     95526\n",
      "                       macro avg     0.8057    0.7454    0.7702     95526\n",
      "                    weighted avg     0.9490    0.9513    0.9495     95526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label_toTest, pred_1, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 500, 100)     7000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 500, 256)     77056       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 256)     102656      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 256)     128256      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 250, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 250, 256)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 250, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 750, 256)     0           max_pooling1d[0][0]              \n",
      "                                                                 max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 15, 256)      0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3840)         0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          491648      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            774         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,800,390\n",
      "Trainable params: 7,800,390\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'flatten/Reshape:0' shape=(None, 3840) dtype=float32>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_output = model.layers[-4].output; activation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 500) dtype=int32>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = model.input; inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_model = tf.keras.Model(inputs, activation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4664/4664 [==============================] - 35s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "train_vecs = activation_model.predict(X_train, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/2961 [..............................] - ETA: 2:39WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0128s vs `on_predict_batch_end` time: 0.0244s). Check your callbacks.\n",
      "2961/2961 [==============================] - 25s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "val_vecs = activation_model.predict(X_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2986/2986 [==============================] - 23s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "test_vecs = activation_model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149217, 3840), (94735, 3840), (95526, 3840))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs.shape, val_vecs.shape, test_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 149217\r"
     ]
    }
   ],
   "source": [
    "for idx, item in train.iterrows():\n",
    "    filename = (Path(\"./activations/text/train\")/Path(item[\"document_type\"])/\n",
    "               (Path(item[\"file_name\"]).with_suffix(\"\").as_posix()+\"_\"+str(item[\"pages\"])))\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(filename, train_vecs[idx])\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.load(\"./activations/text/train/outros/AI_856934_1926211_34_17072013_3.npy\") == train_vecs[3]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 94735\r"
     ]
    }
   ],
   "source": [
    "for idx, item in val.iterrows():\n",
    "    filename = (Path(\"./activations/text/val\")/Path(item[\"document_type\"])/\n",
    "               (Path(item[\"file_name\"]).with_suffix(\"\").as_posix()+\"_\"+str(item[\"pages\"])))\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(filename, val_vecs[idx])\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving example 95526\r"
     ]
    }
   ],
   "source": [
    "for idx, item in test_data.iterrows():\n",
    "    filename = (Path(\"./activations/text/test\")/Path(item[\"document_type\"])/\n",
    "               (Path(item[\"file_name\"]).with_suffix(\"\").as_posix()+\"_\"+str(item[\"pages\"])))\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(filename, test_vecs[idx])\n",
    "    print(f\"Saving example {idx+1}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
